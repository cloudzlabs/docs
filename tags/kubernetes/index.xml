<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on DIGITAL LABS</title>
    <link>http://tech.cloudz-labs.io/tags/kubernetes/</link>
    <description>Recent content in kubernetes on DIGITAL LABS</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 15 Oct 2018 12:30:40 +0900</lastBuildDate>
    
	<atom:link href="http://tech.cloudz-labs.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Spinnaker를 활용한 Helm chart 배포</title>
      <link>http://tech.cloudz-labs.io/posts/spinnaker-deploy-helm-chart/</link>
      <pubDate>Mon, 15 Oct 2018 12:30:40 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/spinnaker-deploy-helm-chart/</guid>
      <description>이 페이지는 Spinnaker에서 Helm chart를 배포하는 방법에 대해 설명합니다.
자세한 내용은 Spinnaker 공식 가이드 문서의 Deploy Helm Charts를 참고하세요.
사전 준비 GitHub 계정 생성 및 저장소 fork GitHub 계정을 생성하고 아래 저장소를 fork 합니다.
https://github.com/YunSangJun/my-charts
GitHub Webhook 설정 GitHub Webhooks 설정하기
GitHub Artifact 설정 GitHub Artifact 설정하기
Application 생성 Spinnaker top menu &amp;gt; Applications &amp;gt; 우측 Actions dropbox &amp;gt; Create Application을 선택합니다.
아래와 같이 내용 입력 후 Create 버튼을 선택합니다.</description>
    </item>
    
    <item>
      <title>경량화 Log Processor &amp; Forwarder : Fluent Bit</title>
      <link>http://tech.cloudz-labs.io/posts/fluent-bit/</link>
      <pubDate>Fri, 27 Jul 2018 14:19:56 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/fluent-bit/</guid>
      <description>Fluent Bit v0.13을 기준으로 작성된 포스팅입니다. https://fluentbit.io
 Log Collector 요즘은 오픈소스화된 다양한 플랫폼이 나오게 되면서 데이터 정보를 수집하기 위해 어려움이 발생합니다. 서로간의 정보의 출처도 다를뿐더러 다양한 데이터 포맷으로 전달해 오는 데이터를 처리해야만 하고 마지막으로 최종 목적지 또한 다를 수 있습니다.
이러한 요구를 만족시키기 위해 2011년 Fluentd라는 프로젝트가 탄생하게 됩니다. Ruby로 작성된 Fluentd는 여러 소스의 데이터를 집계하고 형식이 다른 데이터를 JSON 객체로 통합하여 다른 출력 대상으로 라우팅 할 수 있는 원 스톱 구성 요소인 통합 로깅 레이어로 작동하도록 개발되었습니다.</description>
    </item>
    
    <item>
      <title>Monitoring in kubernetes</title>
      <link>http://tech.cloudz-labs.io/posts/monitoring-in-kubernetes/</link>
      <pubDate>Mon, 23 Jul 2018 08:06:40 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/monitoring-in-kubernetes/</guid>
      <description>Container 환경에서 떠오르는 도전 과제 운영 환경으로 Container 환경 사용 운영 환경에서 Kubernets 사용 비율 증가. =&amp;gt; Container 기반 운영 환경 증가
Container 환경에서 떠오르는 도전 과제 Container 환경을 운영 환경으로 고려하기 시작하면서 운영을 위해 꼭 필요한 모니터링에 대한 관심 증가
[출처 : CNCF https://www.cncf.io/blog/2017/12/06/cloud-native-technologies-scaling-production-applications/]
Cloud Native 환경에서 Monitoring Architecture의 변화 Legacy  고사양의 서버에 Application을 크게 운영 Monitoring Agent를 서버에 설치 Agent가 App 및 OS의 metric 수집해 Backend에 전송  Cloud Native  Application을 작게 운영하고 필요할 때 마다 확장 동적으로 확장하는 서버에 Agent 설치 불가능 Kubernetes API를 통해 동적으로 확장된 서버 endpoint를 discovery Monitoring Backend에서 discovery한 endpoint를 통해 metric 수집  Monitoring Architecture Prometheus  Service Discovery, Metric 수집 및 저장, Alert 기능을 통합해 제공하는 Monitoring 시스템 CNCF의 메인 프로젝트로 Container 기반 Monitoring 시스템의 defactor Kubernetes외의 다른 Cloud Provider에 대한 Service Discovery 기능 제공으로 동적인 Cloud를 효율적을 모니터링 자체 Alert 엔진 보유.</description>
    </item>
    
    <item>
      <title>Logging in kubernetes</title>
      <link>http://tech.cloudz-labs.io/posts/logging-in-kubernetes/</link>
      <pubDate>Wed, 18 Jul 2018 08:06:40 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/logging-in-kubernetes/</guid>
      <description>Cloud Native 환경에서 Logging Architecture의 변화 Legacy  고사양의 서버에 Application을 크게 운영 Log를 Application이 실행 중인 서버 내부에 저장 개발자/운영자는 서버 내부에 접속해 Log를 확인  Cloud Native  Application을 작게 운영하고 필요할 때 마다 확장 다중 인스턴스의 로그를 효율적으로 검색하기 위해 외부 Log 시스템에 저장 개발자/운영자는 서버에 직접 접속하지 않고 외부 Log Backend에서 로그 확인  Cloud Native Logging Architecture Overview DaemonSet Pattern  App Console Log가 각 Node의 Storage에 자동 저장 각 Node의 Agent가 Log를 Aggregator로 전달 Log data를 전/후 처리 후 Backend로 전달  Sidecar Pattern  App Log를 Pod의 Storage에 파일로 저장(Log4j 등 사용) Pod의 Agent가 Log data를 전/후 처리 후 Backend로 전달  DaemonSet Pattern 상세 Architecture  App Console Log가 각 Node의 Storage에 자동 저장 Fluentbit가 각 Node의 Log 수집해 FluentD로 전달 FluentD가 수집한 Log를 전/후 처리 후 ElasticSearch로 전달 Log raw data를 S3와 같은 저장소에 동시 전달 가능(Log Data 백업 활용) Kibana를 통해 ES의 Log data 검색/분석 및 시각화  Sidecar Pattern 상세 Architecture  App Log를 Pod의 Storage에 파일로 저장(Log4j 등 사용) Fluentbit가 저장된 Log를 전/후 처리 후 ElasticSearch로 전달.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(7/8)] Secret</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/secret/</link>
      <pubDate>Fri, 11 May 2018 13:55:54 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/secret/</guid>
      <description>지난 챕터의 ConfigMap에 이어서 이번에는 Secret Object를 보도록 하겠습니다.
Secret 이란? Secret은 비밀번호나 OAuth 토큰값 또는 ssh key 등의 민감한 정보를 유지하기 위해 사용됩니다. 이러한 정보를 Docker 이미지나 Pod에 그대로 정의하기 보다 Secret을 활용하면 더욱 안전하고 유동적으로 사용할 수 있습니다.
Secret 적용하기 Secret 생성 명령어를 통해 생성하기 아래와 같이 kubectl create secret 명령어를 통해 Secret을 생성합니다.
Window OS의 경우 아래 yaml 파일로 Secret을 직접 생성하는 방식으로 사용하세요.
$ kubectl create secret generic db-user-pass --from-literal=user=admin --from-literal=password=1f2d1e2e67df secret &amp;#34;db-user-pass&amp;#34; created 아래와 같이 kubectl get 명령어와 kuberctl describe 명령어를 통해 생성된 Secret을 확인합니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(6/8)] ConfigMap</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/configmap/</link>
      <pubDate>Fri, 11 May 2018 13:55:48 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/configmap/</guid>
      <description>이번에는 Kubernetes에서 제공하는 ConfigMap이라는 Object를 보도록 하겠습니다.
ConfigMap 이란? ConfigMap은 컨테이너 이미지에서 사용하는 환경변수와 같은 세부 정보를 분리하고, 그 환경변수에 대한 값을 외부로 노출 시키지 않고 내부에 존재하는 스토리지에 저장해서 사용하는 방법입니다. 혹시 마이크로서비스 아키텍처에서 사용하는 Spring Cloud Config(Config Server)를 사용한 적이 있다면 동일한 역할을 하는 것인지 하는 생각이 들 수 있는데요. Spring Cloud Config 같은 경우에는 설정 파일 자체를 분리하고 파일에 대한 내용이 변경된다면 자동으로 Refresh 해주는 기능을 가지고 있습니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(5/8)] Ingress</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/ingress/</link>
      <pubDate>Thu, 10 May 2018 18:24:03 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/ingress/</guid>
      <description>Kubernetes에서는 애플리케이션을 외부로 노출하기 위해 Service object를 NodePort로 생성합니다. 그러나 노출 형태가 노드의 IP에 특정 포트(30000-32767)로 제공되기 때문에 호출이 까다롭고 사용자가 서비스로 유입되는 경로도 다양해서 관리가 어려워질 수 있는데요. 이 때, 외부 액세스를 관리하고 서비스를 묶어주는 역할을 하는게 바로 Ingress 입니다.
Ingress 란? 위 그림과 같이 Ingress는 외부 액세스를 관리하고 서비스를 묶어주는 역할을 합니다. Ingress를 만들 때 도메인을 지정할 수 있고 사용자는 그 도메인으로 접속을 하게 되며 도메인 하위의 path 설정을 통해 서비스들을 라우팅할 수 있게 됩니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(4/8)] Mysql DB 연동하기</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/backingservice/</link>
      <pubDate>Tue, 08 May 2018 15:23:03 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/backingservice/</guid>
      <description>지난 챕터에서는 사용한 리소스를 기반으로 애플리케이션의 수를 자동으로 조절할 수 있는 HPA 라는 기능을 적용해 보았습니다. 그렇다면 애플리케이션에 Mysql 또는 Redis 등과 같은 서비스를 연동하고 싶을 땐 어떻게 해야할까요? Kubernetes에서는 애플리케이션에서 필요한 서비스를 Docker Image를 사용하여 바로 구성할 수 있습니다. 물론 대부분이 오픈소스 솔루션에 대한 서비스겠지요. Legacy에 있는 서비스들 역시 연동이 가능하긴 하지만, 여기서는 Docker Image 를 통해 Mysql DB를 구성하고 애플리케이션에 연동해보도록 하겠습니다.
샘플 애플리케이션에 대한 자세한 설명은 Spring의 Accessing data with MySQL 문서를 참고하시기 바랍니다.</description>
    </item>
    
    <item>
      <title>Kubernetes에 구성한 MariaDB(Mysql)의 한글 깨짐 현상 해결방법</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/mariadb-utf8/</link>
      <pubDate>Tue, 10 Apr 2018 15:53:58 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/mariadb-utf8/</guid>
      <description>Why? Kubernetes(a.k.a. K8S)에서 Mysql 또는 Mariadb 이미지를 사용해서 컨테이너를 구성할 때 initialize된 Data에 한글이 깨지는 현상이 발생하는 경우가 있습니다.
구글에서 &amp;ldquo;mysql 한글 깨짐&amp;rdquo;이라고 검색만 해도 같은 문제를 호소하는 분들이 많고, 이를 해결하기 위한 다양한 해결 방법을 가이드하고 있습니다.
하지만 Docker 또는 Kubernetes 환경에서는 대부분이 이미 업로드된 official 이미지를 사용해서 컨테이너를 구성하기 때문에 이를 처리하는데 약간의 수고로움 존재합니다.
이번 세션에서는 K8S 환경에서 mysql(mariadb) 을 구성할 때 한글 깨짐 증상을 해결하고 더 나아가 설정을 자유롭게 할 수 있는 내용을 적어보았습니다.</description>
    </item>
    
    <item>
      <title>Digital Transformation Journey</title>
      <link>http://tech.cloudz-labs.io/posts/digital-transformation-journey/</link>
      <pubDate>Tue, 03 Apr 2018 20:59:36 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/digital-transformation-journey/</guid>
      <description>Software is &amp;ldquo;still&amp;rdquo; eating the world  &amp;ldquo;소프트웨어가 세상을 먹어치우고 있다&amp;hellip;여전히!&amp;rdquo;
 &amp;ldquo;Software is eating the world&amp;rdquo; 는 Marc Andreessen이 아주 오래전에 Wall Street Journal에 올렸던 기고입니다. 그 이후 세상은 호텔을 하나도 소유하지 않은 에어비엔비가 숙박업을, 영화관을 하나도 소유하지 않은 넷플릭스가 미디어 산업을, 오프라인 상점을 하나도 소유하지 않았던(지금은 있지만) 아마존이 리테일 산업을 장악하는 세상으로 바뀌어 버렸습니다.
중요한 것은 &amp;ldquo;아직도&amp;rdquo; 먹어치우고 있다는 것입니다.
사실 몇 년 전만 해도 인터넷 서비스, 미디어, 통신, 리테일 외의 전통 산업에서 Digital Disruption은 올 듯 올 듯 하면서 동인이 잘 생기지 않았습니다.</description>
    </item>
    
    <item>
      <title>K8S App deploy script</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes_deploy_script/</link>
      <pubDate>Fri, 23 Feb 2018 16:42:27 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes_deploy_script/</guid>
      <description>최근 Container 기술이 각광을 받고 있습니다. 그래서 저도 Kubernets 교육을 수강하고 있는데, Kubernets에 배포 한번 하기 참 힘드네요. Project build, Docker image build, Docker push, K8s deploy 총 4개의 과정을 거쳐야 애플리케이션 배포가 끝이 납니다. 도저히 이 과정을 참을 수 없어서 배포 스크립트를 만들었습니다. 사용방법은 아래 설명하였으니, 잘 활용하시기 바랍니다.
사용법 1. deploy.sh 저장 페이지 하단 deploy.sh 파일을 개발중인 프로젝트 루트에 저장합니다.
2. 설정 deploy.sh 파일의 상단 설정을 입력합니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(3/8)] HPA(오토스케일링)</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/hpa/</link>
      <pubDate>Thu, 22 Feb 2018 14:41:49 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/hpa/</guid>
      <description>지난 챕터에서는 이미 배포되어 있는 애플리케이션을 무중단으로 업데이트하는 방법에 대해 보았습니다. 이번에는 이어서 애플리케이션을 자동으로 Scale-out 할수 있는 Horizontal Pod Autoscaler 기능을 적용해보도록 하겠습니다.
Horizontal Pod Autoscaler 란 Horizontal Pod Autoscaler는 지정된 CPU 사용률을 기반으로 Replication Controller, Deployment 또는 Replica Set의 Pod 수를 자동으로 조정합니다. Kubernetes에서는 CPU 자원에 대한 사용량을 다음과 같은 식으로 계산하여 Pod을 자동 Scale-out 할 수 있습니다.
[CPU example] TargetNumOfPods = ceil(sum(CurrentPodsCPUUtilization) / Target) 주기적으로 Pod의 자원 사용을 체크하고, 특정 시간의 여유를 두고 downscale/upscale이 이루어지는데, 이는 kube-controller-manager가 담당합니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(2/8)] Rolling Update(무중단 배포)</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/rolling-update/</link>
      <pubDate>Thu, 22 Feb 2018 14:41:42 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/rolling-update/</guid>
      <description>지난 챕터에서는 Kubernetes 환경에서 애플리케이션을 배포하고 접속하는 방법을 알아보았습니다. 그렇다면 이미 배포되어 있는 애플리케이션을 업데이트할 때 중단 없이 처리할 수 있을까요?? 네. 가능합니다! Kubernetes에서는 중단 없이 애플리케이션을 배포할 수 있도록 Rolling Update라는 기능을 지원하고 있습니다. 지난 챕터에서 간단히 나오긴 했지만 다시 한번 자세히 알아봅시다.
Rolling Update 란? 서비스 중단 없이 애플리케이션을 업데이트 하기 위해서, Kubernetes에서는 rolling update라는 기능을 지원합니다. 이 기능을 통해서 전체 Pod을 일시에 중단/업데이트 하는 것이 아니라, 한번에 n개씩 Pod을 순차적으로 업데이트할 수 있습니다.</description>
    </item>
    
    <item>
      <title>[Kubernetes 활용(1/8)] 시작하기</title>
      <link>http://tech.cloudz-labs.io/posts/kubernetes/getting-start/</link>
      <pubDate>Wed, 21 Feb 2018 11:33:28 +0900</pubDate>
      
      <guid>http://tech.cloudz-labs.io/posts/kubernetes/getting-start/</guid>
      <description>언젠가부터 클라우드 열풍이 불어 닥치고 있습니다. 기술의 변화를 보면 IaaS보다는 PaaS나 SaaS를 선호하고, VM에서 직접 컨트롤 하기 보다는 컨테이너, 서버리스 형태의 기술들이 뜨고 있습니다. 저도 그러한 이유로 작년부터 조금씩 회사에서 Kubernetes 스터디를 하고 있네요. 이번 첫번째 챕터에서는 Kubernetes를 처음 접하는 사용자를 위해 Kubernetes 환경에서 애플리케이션을 배포/접속하고 관리하는 기본적인 방법에 대해 보도록 하겠습니다.
시작하기 전에 애플리케이션 배포를 진행하기 전에 이해가 필요한 기본 개념입니다.
Kubernetes  Kubernetes는 2014년 Google이 시작한 프로젝트로, 애플리케이션 컨테이너의 배포, 스케일링, 오퍼레이팅을 자동화 해주는 오픈 소스 플랫폼입니다.</description>
    </item>
    
  </channel>
</rss>